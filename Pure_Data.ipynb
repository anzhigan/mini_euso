{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba0b95f",
   "metadata": {
    "id": "5ba0b95f",
    "outputId": "cb578607-c3e0-4e36-f98b-353d48cf6bd2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 15:13:44.640788: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:7630] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-06-30 15:13:44.640829: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-06-30 15:13:44.640847: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-30 15:13:44.649051: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-30 15:13:45.513748: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/anzhigun/mini_euso/mini_euso_venv/lib/python3.8/site-packages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/anzhigun/mini_euso/mini_euso_venv/lib/python3.8/site-packages/tensorflow/python/ops/distributions/bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "from numpy import load\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, matthews_corrcoef, confusion_matrix\n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e774f18",
   "metadata": {
    "id": "7e774f18"
   },
   "outputs": [],
   "source": [
    "SESSIONS = ['05', '06', '07', '08', '09', '11', '12', '13', '14']\n",
    "data = {}\n",
    "for s in SESSIONS:\n",
    "    data[s] =  np.load('data/markered_data/{0}/data_8x8x48_{0}.npz'.format(s, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c464c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pure_data = np.concatenate([data['05']['arr_0'], data['06']['arr_0'], data['07']['arr_0'], data['08']['arr_0'],\n",
    "                    data['09']['arr_0'], data['11']['arr_0'], data['12']['arr_0'], data['13']['arr_0']], axis = 0)\n",
    "\n",
    "Y_train_pure_data = np.concatenate([data['05']['arr_1'], data['06']['arr_1'], data['07']['arr_1'], data['08']['arr_1'],\n",
    "                    data['09']['arr_1'], data['11']['arr_1'], data['12']['arr_1'], data['13']['arr_1']], axis = 0)\n",
    "\n",
    "X_test_pure_data = data['14']['arr_0']\n",
    "\n",
    "Y_test_pure_data = data['14']['arr_1']\n",
    "\n",
    "\n",
    "X_train_pure_data = preprocessing.normalize(X_train_pure_data)\n",
    "# Y_train_pure_data[Y_train_pure_data <= 0] = -1\n",
    "X_test_pure_data = preprocessing.normalize(X_test_pure_data)\n",
    "# Y_test_pure_data[Y_test_pure_data <= 0] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473ac3ae",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7c89bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs\n",
      "liblinear\n",
      "newton-cg\n",
      "newton-cholesky\n",
      "sag\n",
      "saga\n"
     ]
    }
   ],
   "source": [
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "TRAIN_RESULTS = {}\n",
    "TEST_RESULTS = {}\n",
    "\n",
    "\n",
    "for slv in solvers:\n",
    "    print(slv)\n",
    "    #model creating\n",
    "    model = LogisticRegression(solver=slv, max_iter=300, random_state=0, C=0.7).fit(X_train_pure_data, Y_train_pure_data)\n",
    "    \n",
    "    preds_proba_train = model.predict_proba(X_train_pure_data)[:, 1]\n",
    "    preds_proba_test = model.predict_proba(X_test_pure_data)[:, 1]\n",
    "    preds_train = model.predict(X_train_pure_data)\n",
    "    preds_test = model.predict(X_test_pure_data)\n",
    "    \n",
    "    TRAIN_RESULTS[slv] = [roc_auc_score(Y_train_pure_data, preds_proba_train), \n",
    "                          average_precision_score(Y_train_pure_data, preds_proba_train), \n",
    "                          matthews_corrcoef(Y_train_pure_data, preds_train),\n",
    "                        f1_score(Y_train_pure_data, preds_train)]\n",
    "    TEST_RESULTS[slv] = [roc_auc_score(Y_test_pure_data, preds_proba_test), \n",
    "                          average_precision_score(Y_test_pure_data, preds_proba_test), \n",
    "                          matthews_corrcoef(Y_test_pure_data, preds_test),\n",
    "                        f1_score(Y_test_pure_data, preds_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70872fa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEST_RESULTS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mTEST_RESULTS\u001b[49m, TRAIN_RESULTS\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TEST_RESULTS' is not defined"
     ]
    }
   ],
   "source": [
    "TEST_RESULTS, TRAIN_RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db1668",
   "metadata": {},
   "source": [
    "### Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5905da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params):\n",
    "    l_r, loss_function, activation_fucntion, hidden_layer, hidden_layer_2, input_layer, output_layer, metr = params[0], params[1], params[2], params[3], params[4], params[5], params[6], params[7]\n",
    "    print('l_r:', l_r, 'loss_function:',loss_function, 'activation_fucntion:', activation_fucntion,\n",
    "          'hidden_layer:', hidden_layer, 'hidden_layer_2:', hidden_layer_2,\n",
    "          'input_layer:', input_layer, 'output_layer:', output_layer, 'metr:', metr)\n",
    "    model = keras.Sequential()\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            units = hidden_layer,\n",
    "            activation=\"relu\",\n",
    "            input_shape=(input_layer,)\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            units = hidden_layer_2,\n",
    "            activation=\"relu\",\n",
    "            input_shape=(hidden_layer,)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            units = output_layer,\n",
    "            activation = 'sigmoid')\n",
    "        )\n",
    "    #////////////////////////////////////////////////////////\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = l_r),\n",
    "        # optimizer = tf.keras.optimizers.legacy.SGD(learning_rate = l_r),\n",
    "#         optimizer = tf.keras.optimizers.legacy.SGD(learning_rate = l_r, nesterov = True),\n",
    "        loss = loss_function,\n",
    "        metrics = metr\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a5e1b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = tf.keras.metrics.AUC(\n",
    "    num_thresholds=200,\n",
    "    curve='ROC',\n",
    "    summation_method='interpolation',\n",
    "    name=None,\n",
    "    dtype=None,\n",
    "    thresholds=None,\n",
    "    multi_label=False,\n",
    "    num_labels=None,\n",
    "    label_weights=None,\n",
    "    from_logits=False\n",
    ")\n",
    "\n",
    "pr_auc = tf.keras.metrics.AUC(\n",
    "    num_thresholds=200,\n",
    "    curve='PR',\n",
    "    summation_method='interpolation',\n",
    "    name=None,\n",
    "    dtype=None,\n",
    "    thresholds=None,\n",
    "    multi_label=False,\n",
    "    num_labels=None,\n",
    "    label_weights=None,\n",
    "    from_logits=False\n",
    ")\n",
    "\n",
    "f1_score = tf.keras.metrics.F1Score(\n",
    "    average='micro', threshold=0.5, name='f1_score', dtype=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33c30795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(X_train, Y_train, X_test, Y_test, params, BATCHES, EPOCHS_COUNT):\n",
    "\n",
    "    #создаётся модель с определёнными ранее параметрами\n",
    "    model = build_model(params)\n",
    "\n",
    "    train_history = model.fit(X_train, Y_train, batch_size = BATCHES, epochs = EPOCHS_COUNT)\n",
    "    results_test = model.evaluate(X_test, Y_test, batch_size = BATCHES)\n",
    "    \n",
    "    y_train_pred_proba = model.predict(X_train)\n",
    "    y_test_pred_proba = model.predict(X_test)\n",
    "    y_train_pred = y_train_pred_proba.copy()\n",
    "    y_test_pred = y_test_pred_proba.copy()\n",
    "    \n",
    "    y_train_pred[y_train_pred >= 0.5] = 1\n",
    "    y_train_pred[y_train_pred < 0.5] = 0\n",
    "    y_test_pred[y_test_pred >= 0.5] = 1\n",
    "    y_test_pred[y_test_pred < 0.5] = 0\n",
    "    \n",
    "    train_score = [roc_auc(Y_train, y_train_pred_proba), \n",
    "                   pr_auc(Y_train, y_train_pred_proba),\n",
    "                   matthews_corrcoef(Y_train, y_train_pred),\n",
    "                   train_history.history['f1_score'][-1],\n",
    "                   (confusion_matrix(Y_train, y_train_pred).ravel())\n",
    "                  ]\n",
    "    test_score = [roc_auc(Y_test, y_test_pred_proba), \n",
    "                  pr_auc(Y_test, y_test_pred_proba), \n",
    "                  matthews_corrcoef(Y_test, y_test_pred),\n",
    "                  results_test[1],\n",
    "                  (confusion_matrix(Y_test, y_test_pred).ravel())\n",
    "                 ]\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82134c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train, Y_train, X_test, Y_test, l_rates, activation, loss_function, input_layer, hidden_layers_1,\n",
    "                  hidden_layers_2, output_layer, metr):\n",
    "    RESULT = {}\n",
    "    PROGONS = 1\n",
    "    for progon in range(PROGONS):\n",
    "        print(\"progon # =\", progon)\n",
    "        for activ in activation:\n",
    "            for h_1 in hidden_layers_1:\n",
    "                for h_2 in hidden_layers_2:\n",
    "                    print('##################################################################################', '\\n'\n",
    "                          '| Число узлов первого и второго скрытых слоёв:', h_1, \" \", h_2)\n",
    "                    params = [l_rates, loss_function, activ, h_1, h_2, input_layer, output_layer, metr]\n",
    "                    TRAIN_RESULTS, TEST_RESULTS = validation(X_train, Y_train, X_test, Y_test, params, BATCHES = 254, EPOCHS_COUNT = 150)\n",
    "                    RESULT[' '.join(map(str, params))] = [TEST_RESULTS, TRAIN_RESULTS]\n",
    "\n",
    "    return RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bb6ff35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progon # = 0\n",
      "################################################################################## \n",
      "| Число узлов первого и второго скрытых слоёв: 128   32\n",
      "l_r: <keras.src.optimizers.schedules.learning_rate_schedule.ExponentialDecay object at 0x7fb8ded3e9a0> loss_function: <keras.src.losses.BinaryCrossentropy object at 0x7fb8ded3e0a0> activation_fucntion: tanh hidden_layer: 128 hidden_layer_2: 32 input_layer: 48 output_layer: 1 metr: F1Score(name=f1_score,dtype=float32,average=micro,threshold=0.5)\n",
      "Epoch 1/150\n",
      "2033/2033 [==============================] - 5s 2ms/step - loss: 0.2653 - f1_score: 0.1537\n",
      "Epoch 2/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.2153 - f1_score: 0.3232\n",
      "Epoch 3/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1726 - f1_score: 0.5225\n",
      "Epoch 4/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1576 - f1_score: 0.5753\n",
      "Epoch 5/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1441 - f1_score: 0.6271\n",
      "Epoch 6/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1380 - f1_score: 0.6449\n",
      "Epoch 7/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1339 - f1_score: 0.6614\n",
      "Epoch 8/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1326 - f1_score: 0.6637\n",
      "Epoch 9/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1341 - f1_score: 0.6601\n",
      "Epoch 10/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1295 - f1_score: 0.6737\n",
      "Epoch 11/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1264 - f1_score: 0.6817\n",
      "Epoch 12/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1248 - f1_score: 0.6870\n",
      "Epoch 13/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1223 - f1_score: 0.6916\n",
      "Epoch 14/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1222 - f1_score: 0.6926\n",
      "Epoch 15/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1180 - f1_score: 0.7036\n",
      "Epoch 16/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1182 - f1_score: 0.7036\n",
      "Epoch 17/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1167 - f1_score: 0.7068\n",
      "Epoch 18/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1136 - f1_score: 0.7152\n",
      "Epoch 19/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1135 - f1_score: 0.7151\n",
      "Epoch 20/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1121 - f1_score: 0.7196\n",
      "Epoch 21/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1115 - f1_score: 0.7228\n",
      "Epoch 22/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1120 - f1_score: 0.7232\n",
      "Epoch 23/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1109 - f1_score: 0.7230\n",
      "Epoch 24/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1079 - f1_score: 0.7342\n",
      "Epoch 25/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1089 - f1_score: 0.7300\n",
      "Epoch 26/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1089 - f1_score: 0.7300\n",
      "Epoch 27/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1076 - f1_score: 0.7345\n",
      "Epoch 28/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1072 - f1_score: 0.7337\n",
      "Epoch 29/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1038 - f1_score: 0.7442\n",
      "Epoch 30/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1052 - f1_score: 0.7390\n",
      "Epoch 31/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1045 - f1_score: 0.7414\n",
      "Epoch 32/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1044 - f1_score: 0.7439\n",
      "Epoch 33/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1040 - f1_score: 0.7429\n",
      "Epoch 34/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1039 - f1_score: 0.7444\n",
      "Epoch 35/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1027 - f1_score: 0.7500\n",
      "Epoch 36/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1016 - f1_score: 0.7508\n",
      "Epoch 37/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1013 - f1_score: 0.7512\n",
      "Epoch 38/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1008 - f1_score: 0.7542\n",
      "Epoch 39/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1008 - f1_score: 0.7519\n",
      "Epoch 40/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1034 - f1_score: 0.7482\n",
      "Epoch 41/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1004 - f1_score: 0.7541\n",
      "Epoch 42/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0999 - f1_score: 0.7563\n",
      "Epoch 43/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.1004 - f1_score: 0.7543\n",
      "Epoch 44/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0987 - f1_score: 0.7571\n",
      "Epoch 45/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0976 - f1_score: 0.7606\n",
      "Epoch 46/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0995 - f1_score: 0.7560\n",
      "Epoch 47/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0974 - f1_score: 0.7621\n",
      "Epoch 48/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0974 - f1_score: 0.7598\n",
      "Epoch 49/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0972 - f1_score: 0.7615\n",
      "Epoch 50/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0980 - f1_score: 0.7612\n",
      "Epoch 51/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0961 - f1_score: 0.7630\n",
      "Epoch 52/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0962 - f1_score: 0.7660\n",
      "Epoch 53/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0961 - f1_score: 0.7653\n",
      "Epoch 54/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0955 - f1_score: 0.7679\n",
      "Epoch 55/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0974 - f1_score: 0.7623\n",
      "Epoch 56/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0946 - f1_score: 0.7695\n",
      "Epoch 57/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0945 - f1_score: 0.7687\n",
      "Epoch 58/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0953 - f1_score: 0.7672\n",
      "Epoch 59/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0939 - f1_score: 0.7718\n",
      "Epoch 60/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0950 - f1_score: 0.7681\n",
      "Epoch 61/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0933 - f1_score: 0.7721\n",
      "Epoch 62/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0931 - f1_score: 0.7732\n",
      "Epoch 63/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0943 - f1_score: 0.7703\n",
      "Epoch 64/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0932 - f1_score: 0.7729\n",
      "Epoch 65/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0938 - f1_score: 0.7719\n",
      "Epoch 66/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0929 - f1_score: 0.7747\n",
      "Epoch 67/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0933 - f1_score: 0.7728\n",
      "Epoch 68/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0927 - f1_score: 0.7740\n",
      "Epoch 69/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0931 - f1_score: 0.7742\n",
      "Epoch 70/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0927 - f1_score: 0.7738\n",
      "Epoch 71/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0911 - f1_score: 0.7761\n",
      "Epoch 72/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0921 - f1_score: 0.7752\n",
      "Epoch 73/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0919 - f1_score: 0.7750\n",
      "Epoch 74/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0921 - f1_score: 0.7757\n",
      "Epoch 75/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0914 - f1_score: 0.7764\n",
      "Epoch 76/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0922 - f1_score: 0.7752\n",
      "Epoch 77/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0907 - f1_score: 0.7791\n",
      "Epoch 78/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0915 - f1_score: 0.7767\n",
      "Epoch 79/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0917 - f1_score: 0.7769\n",
      "Epoch 80/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0914 - f1_score: 0.7777\n",
      "Epoch 81/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0905 - f1_score: 0.7795\n",
      "Epoch 82/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0914 - f1_score: 0.7791\n",
      "Epoch 83/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0904 - f1_score: 0.7796\n",
      "Epoch 84/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0906 - f1_score: 0.7794\n",
      "Epoch 85/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0907 - f1_score: 0.7791\n",
      "Epoch 86/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0907 - f1_score: 0.7790\n",
      "Epoch 87/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0906 - f1_score: 0.7806\n",
      "Epoch 88/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0908 - f1_score: 0.7804\n",
      "Epoch 89/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0904 - f1_score: 0.7813\n",
      "Epoch 90/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0908 - f1_score: 0.7807\n",
      "Epoch 91/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0899 - f1_score: 0.7821\n",
      "Epoch 92/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0894 - f1_score: 0.7835\n",
      "Epoch 93/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0891 - f1_score: 0.7821\n",
      "Epoch 94/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0891 - f1_score: 0.7838\n",
      "Epoch 95/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0884 - f1_score: 0.7844\n",
      "Epoch 96/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0882 - f1_score: 0.7831\n",
      "Epoch 97/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0887 - f1_score: 0.7839\n",
      "Epoch 98/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0889 - f1_score: 0.7838\n",
      "Epoch 99/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0880 - f1_score: 0.7855\n",
      "Epoch 100/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0887 - f1_score: 0.7829\n",
      "Epoch 101/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0888 - f1_score: 0.7838\n",
      "Epoch 102/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0881 - f1_score: 0.7853\n",
      "Epoch 103/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0885 - f1_score: 0.7858\n",
      "Epoch 104/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0881 - f1_score: 0.7852\n",
      "Epoch 105/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0888 - f1_score: 0.7833\n",
      "Epoch 106/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0871 - f1_score: 0.7873\n",
      "Epoch 107/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0880 - f1_score: 0.7861\n",
      "Epoch 108/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0871 - f1_score: 0.7884\n",
      "Epoch 109/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0877 - f1_score: 0.7856\n",
      "Epoch 110/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0874 - f1_score: 0.7872\n",
      "Epoch 111/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0868 - f1_score: 0.7900\n",
      "Epoch 112/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0870 - f1_score: 0.7885\n",
      "Epoch 113/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0878 - f1_score: 0.7876\n",
      "Epoch 114/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0874 - f1_score: 0.7876\n",
      "Epoch 115/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0867 - f1_score: 0.7887\n",
      "Epoch 116/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0874 - f1_score: 0.7891\n",
      "Epoch 117/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0865 - f1_score: 0.7893\n",
      "Epoch 118/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0865 - f1_score: 0.7897\n",
      "Epoch 119/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0861 - f1_score: 0.7921\n",
      "Epoch 120/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0866 - f1_score: 0.7894\n",
      "Epoch 121/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0862 - f1_score: 0.7894\n",
      "Epoch 122/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0859 - f1_score: 0.7918\n",
      "Epoch 123/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0866 - f1_score: 0.7897\n",
      "Epoch 124/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0868 - f1_score: 0.7883\n",
      "Epoch 125/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0855 - f1_score: 0.7922\n",
      "Epoch 126/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0856 - f1_score: 0.7918\n",
      "Epoch 127/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0858 - f1_score: 0.7907\n",
      "Epoch 128/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0859 - f1_score: 0.7920\n",
      "Epoch 129/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0861 - f1_score: 0.7918\n",
      "Epoch 130/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0863 - f1_score: 0.7911\n",
      "Epoch 131/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0854 - f1_score: 0.7932\n",
      "Epoch 132/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0852 - f1_score: 0.7925\n",
      "Epoch 133/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0854 - f1_score: 0.7932\n",
      "Epoch 134/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0856 - f1_score: 0.7924\n",
      "Epoch 135/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0860 - f1_score: 0.7916\n",
      "Epoch 136/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0857 - f1_score: 0.7919\n",
      "Epoch 137/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0860 - f1_score: 0.7920\n",
      "Epoch 138/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0854 - f1_score: 0.7933\n",
      "Epoch 139/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0861 - f1_score: 0.7915\n",
      "Epoch 140/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0853 - f1_score: 0.7935\n",
      "Epoch 141/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0855 - f1_score: 0.7927\n",
      "Epoch 142/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0852 - f1_score: 0.7924\n",
      "Epoch 143/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0855 - f1_score: 0.7938\n",
      "Epoch 144/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0854 - f1_score: 0.7919\n",
      "Epoch 145/150\n",
      "2033/2033 [==============================] - 4s 2ms/step - loss: 0.0846 - f1_score: 0.7941\n",
      "Epoch 146/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0855 - f1_score: 0.7936\n",
      "Epoch 147/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0852 - f1_score: 0.7929\n",
      "Epoch 148/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0842 - f1_score: 0.7974\n",
      "Epoch 149/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0843 - f1_score: 0.7949\n",
      "Epoch 150/150\n",
      "2033/2033 [==============================] - 3s 2ms/step - loss: 0.0843 - f1_score: 0.7960\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.0733 - f1_score: 0.8133\n",
      "16132/16132 [==============================] - 14s 874us/step\n",
      "2048/2048 [==============================] - 2s 883us/step\n"
     ]
    }
   ],
   "source": [
    "initial_learning_rate = 0.005\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "\n",
    "res = fit(X_train_pure_data, Y_train_pure_data, X_test_pure_data, Y_test_pure_data, l_rates = lr_schedule, \n",
    "          #'relu', 'sigmoid', 'tanh'\n",
    "          loss_function = keras.losses.BinaryCrossentropy(), activation = ['tanh'],\n",
    "          hidden_layers_1 = [128], hidden_layers_2 = [32], input_layer = 48, output_layer = 1, metr = f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d890a540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<keras.src.optimizers.schedules.learning_rate_schedule.ExponentialDecay object at 0x7fb8ded3e9a0> <keras.src.losses.BinaryCrossentropy object at 0x7fb8ded3e0a0> tanh 128 32 48 1 F1Score(name=f1_score,dtype=float32,average=micro,threshold=0.5)': [[<tf.Tensor: shape=(), dtype=float32, numpy=0.9727864>,\n",
       "   <tf.Tensor: shape=(), dtype=float32, numpy=0.8697278>,\n",
       "   0.8044419674120792,\n",
       "   0.8132655620574951,\n",
       "   array([60401,   393,  1223,  3519])],\n",
       "  [<tf.Tensor: shape=(), dtype=float32, numpy=0.9727289>,\n",
       "   <tf.Tensor: shape=(), dtype=float32, numpy=0.8696118>,\n",
       "   0.7941929854923013,\n",
       "   0.7960426807403564,\n",
       "   array([470559,   6511,   8117,  31037])]]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab3d5e",
   "metadata": {},
   "source": [
    "_________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d5439af",
   "metadata": {
    "id": "9d5439af"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68baeb47",
   "metadata": {
    "id": "68baeb47"
   },
   "outputs": [],
   "source": [
    "## train data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TrainData(Dataset):\n",
    "\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "## test data\n",
    "class TestData(Dataset):\n",
    "\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13a58e",
   "metadata": {
    "id": "1e13a58e"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassification, self).__init__()\n",
    "        # Number of input features is 48.\n",
    "        self.layer_1 = nn.Linear(48, 96)\n",
    "        self.layer_2 = nn.Linear(96, 64)\n",
    "        self.layer_out = nn.Linear(64, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(96)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efa7fb",
   "metadata": {
    "id": "a5efa7fb",
    "outputId": "309ef54f-00d6-4df8-f509-13109d22ff59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89989941",
   "metadata": {
    "id": "89989941"
   },
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f69acc",
   "metadata": {
    "id": "f3f69acc"
   },
   "outputs": [],
   "source": [
    "def create_train_test_data(test_s, data):\n",
    "    train_X_data = []\n",
    "    train_Y_data = []\n",
    "\n",
    "    for s in SESSION:\n",
    "        if s != test_s:\n",
    "            train_X_data.append(data[s]['arr_0'])\n",
    "            train_Y_data.append(data[s]['arr_1'])\n",
    "\n",
    "    X_train = preprocessing.normalize(np.concatenate(train_X_data))\n",
    "    Y_train = np.concatenate(train_Y_data)\n",
    "\n",
    "    X_test = preprocessing.normalize(data[test_s]['arr_0'])\n",
    "    Y_test = data[test_s]['arr_1']\n",
    "\n",
    "    train_data = TrainData(torch.FloatTensor(X_train), torch.FloatTensor(Y_train))\n",
    "    test_data = TestData(torch.FloatTensor(X_test), torch.FloatTensor(Y_test))\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a93f5",
   "metadata": {
    "id": "a71a93f5"
   },
   "outputs": [],
   "source": [
    "from torchmetrics import AUROC, MatthewsCorrCoef, PrecisionRecallCurve, AveragePrecision\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def metrics(model, data):\n",
    "    X = data.X_data\n",
    "    Y = data.y_data.int()\n",
    "    X_loader = DataLoader(dataset=X, batch_size=len(X))\n",
    "\n",
    "    y_pred_list = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch in X_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_pred = torch.sigmoid(model(X_batch))\n",
    "            y_pred_tag = torch.round(y_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list][0]\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(Y, y_pred_list).ravel()\n",
    "\n",
    "    auroc = AUROC(task=\"binary\")\n",
    "    average_precision = AveragePrecision(task=\"binary\")\n",
    "    matthews_corrcoef = MatthewsCorrCoef(task='binary')\n",
    "\n",
    "    Y_pred_tensor = torch.tensor(y_pred_list)\n",
    "    PR_AUC = average_precision(Y_pred_tensor, Y)\n",
    "    ROC_AUC = auroc(Y_pred_tensor, Y)\n",
    "    MCC = matthews_corrcoef(Y_pred_tensor, Y)\n",
    "    print(ROC_AUC, PR_AUC, MCC)\n",
    "    return ROC_AUC, PR_AUC, (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e95e7e5",
   "metadata": {
    "id": "5e95e7e5"
   },
   "outputs": [],
   "source": [
    "def clf_fit(train_data, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for e in range(1, 8):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        train_loader = DataLoader(dataset = train_data, batch_size = 128, shuffle = True)\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "        losses.append(epoch_loss)\n",
    "\n",
    "        print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    return losses, model\n",
    "\n",
    "def cross_val_score(data, LEARNING_RATE = 0.001):\n",
    "    TRAIN_RESULTS_BY_SESSION = {}\n",
    "    TEST_RESULTS_BY_SESSION = {}\n",
    "    LOSSES = {}\n",
    "\n",
    "    for s in SESSION:\n",
    "        print(\"SESSION №\", s)\n",
    "        #каждая сессия выбирается валидационной, остальные обучающими\n",
    "        train_data, test_data = create_train_test_data(s, data)\n",
    "\n",
    "        #создаётся модель с определёнными ранее параметрами\n",
    "        model = BinaryClassification()\n",
    "        model.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        #обучим модель\n",
    "        losses, trained_model = clf_fit(train_data, model, criterion, optimizer)\n",
    "        LOSSES[s] = losses\n",
    "\n",
    "        #метрика\n",
    "        AUC_train, MCC_train, (tn_train, fp_train, fn_train, tp_train) = metrics(trained_model, train_data)\n",
    "        AUC_test, MCC_test, (tn_test, fp_test, fn_test, tp_test) = metrics(trained_model, test_data)\n",
    "\n",
    "        #результаты обучения (loss,auc за EPOCHS_COUNT эпох) сохраняются в словаре TRAIN_RESULTS_BY_SESSION\n",
    "        TRAIN_RESULTS_BY_SESSION[s] = [AUC_train, MCC_train, (tn_train, fp_train, fn_train, tp_train)]\n",
    "        TEST_RESULTS_BY_SESSION[s] = [AUC_test, MCC_test, (tn_test, fp_test, fn_test, tp_test)]\n",
    "\n",
    "    return TRAIN_RESULTS_BY_SESSION, TEST_RESULTS_BY_SESSION, LOSSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb08129",
   "metadata": {
    "id": "0fb08129",
    "outputId": "35150c16-7f0d-4811-85a1-9d1d5f025f17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SESSION № 05\n",
      "Epoch 001: | Loss: 0.00000 | Acc: 25.036\n",
      "Epoch 002: | Loss: 0.00000 | Acc: 25.070\n",
      "Epoch 003: | Loss: 0.00000 | Acc: 25.074\n",
      "Epoch 004: | Loss: 0.00000 | Acc: 25.034\n",
      "Epoch 005: | Loss: 0.00000 | Acc: 25.010\n",
      "Epoch 006: | Loss: 0.00000 | Acc: 25.006\n",
      "Epoch 007: | Loss: 0.00000 | Acc: 25.080\n",
      "tensor(0.2657) tensor(0.0597) tensor(-0.3113)\n",
      "tensor(0.2909) tensor(0.0699) tensor(-0.2664)\n",
      "SESSION № 06\n",
      "Epoch 001: | Loss: 0.00000 | Acc: 69.567\n",
      "Epoch 002: | Loss: 0.00000 | Acc: 69.477\n",
      "Epoch 003: | Loss: 0.00000 | Acc: 69.462\n",
      "Epoch 004: | Loss: 0.00000 | Acc: 69.523\n",
      "Epoch 005: | Loss: 0.00000 | Acc: 69.632\n",
      "Epoch 006: | Loss: 0.00000 | Acc: 69.500\n",
      "Epoch 007: | Loss: 0.00000 | Acc: 69.446\n",
      "tensor(0.5617) tensor(0.0892) tensor(0.0880)\n",
      "tensor(0.5481) tensor(0.0873) tensor(0.0635)\n",
      "SESSION № 07\n",
      "Epoch 001: | Loss: 0.00000 | Acc: 76.770\n",
      "Epoch 002: | Loss: 0.00000 | Acc: 76.716\n",
      "Epoch 003: | Loss: 0.00000 | Acc: 76.763\n",
      "Epoch 004: | Loss: 0.00000 | Acc: 76.703\n",
      "Epoch 005: | Loss: 0.00000 | Acc: 76.757\n",
      "Epoch 006: | Loss: 0.00000 | Acc: 76.729\n",
      "Epoch 007: | Loss: 0.00000 | Acc: 76.752\n",
      "tensor(0.6981) tensor(0.1708) tensor(0.2929)\n",
      "tensor(0.5707) tensor(0.0801) tensor(0.1111)\n",
      "SESSION № 08\n",
      "Epoch 001: | Loss: 0.00000 | Acc: 65.456\n",
      "Epoch 002: | Loss: 0.00000 | Acc: 65.523\n",
      "Epoch 003: | Loss: 0.00000 | Acc: 65.451\n",
      "Epoch 004: | Loss: 0.00000 | Acc: 65.475\n",
      "Epoch 005: | Loss: 0.00000 | Acc: 65.396\n",
      "Epoch 006: | Loss: 0.00000 | Acc: 65.576\n",
      "Epoch 007: | Loss: 0.00000 | Acc: 65.544\n",
      "tensor(0.6021) tensor(0.1005) tensor(0.1242)\n",
      "tensor(0.5953) tensor(0.0963) tensor(0.1121)\n",
      "SESSION № 09\n",
      "Epoch 001: | Loss: 0.00000 | Acc: 73.612\n",
      "Epoch 002: | Loss: 0.00000 | Acc: 73.652\n",
      "Epoch 003: | Loss: 0.00000 | Acc: 73.603\n",
      "Epoch 004: | Loss: 0.00000 | Acc: 73.621\n",
      "Epoch 005: | Loss: 0.00000 | Acc: 73.589\n",
      "Epoch 006: | Loss: 0.00000 | Acc: 73.576\n",
      "Epoch 007: | Loss: 0.00000 | Acc: 73.695\n",
      "tensor(0.6291) tensor(0.1299) tensor(0.2112)\n",
      "tensor(0.6316) tensor(0.1679) tensor(0.3003)\n",
      "SESSION № 11\n",
      "Epoch 001: | Loss: 0.00000 | Acc: 28.874\n",
      "Epoch 002: | Loss: 0.00000 | Acc: 28.781\n",
      "Epoch 003: | Loss: 0.00000 | Acc: 28.918\n",
      "Epoch 004: | Loss: 0.00000 | Acc: 28.863\n",
      "Epoch 005: | Loss: 0.00000 | Acc: 28.810\n",
      "Epoch 006: | Loss: 0.00000 | Acc: 28.839\n",
      "Epoch 007: | Loss: 0.00000 | Acc: 28.797\n",
      "tensor(0.4249) tensor(0.0670) tensor(-0.1102)\n",
      "tensor(0.4159) tensor(0.0646) tensor(-0.1230)\n",
      "SESSION № 12\n",
      "Epoch 001: | Loss: 0.00000 | Acc: 48.276\n",
      "Epoch 002: | Loss: 0.00000 | Acc: 48.109\n",
      "Epoch 003: | Loss: 0.00000 | Acc: 48.183\n",
      "Epoch 004: | Loss: 0.00000 | Acc: 48.230\n",
      "Epoch 005: | Loss: 0.00000 | Acc: 48.228\n",
      "Epoch 006: | Loss: 0.00000 | Acc: 48.256\n",
      "Epoch 007: | Loss: 0.00000 | Acc: 48.212\n",
      "tensor(0.5132) tensor(0.0781) tensor(0.0142)\n",
      "tensor(0.5256) tensor(0.0714) tensor(0.0261)\n",
      "SESSION № 13\n",
      "Epoch 001: | Loss: 0.00000 | Acc: 23.373\n",
      "Epoch 002: | Loss: 0.00000 | Acc: 23.416\n",
      "Epoch 003: | Loss: 0.00000 | Acc: 23.340\n",
      "Epoch 004: | Loss: 0.00000 | Acc: 23.330\n",
      "Epoch 005: | Loss: 0.00000 | Acc: 23.372\n",
      "Epoch 006: | Loss: 0.00000 | Acc: 23.373\n",
      "Epoch 007: | Loss: 0.00000 | Acc: 23.361\n",
      "tensor(0.3646) tensor(0.0617) tensor(-0.2007)\n",
      "tensor(0.3447) tensor(0.0647) tensor(-0.2745)\n",
      "SESSION № 14\n",
      "Epoch 001: | Loss: 0.00000 | Acc: 35.899\n",
      "Epoch 002: | Loss: 0.00000 | Acc: 35.953\n",
      "Epoch 003: | Loss: 0.00000 | Acc: 35.837\n",
      "Epoch 004: | Loss: 0.00000 | Acc: 35.894\n",
      "Epoch 005: | Loss: 0.00000 | Acc: 35.834\n",
      "Epoch 006: | Loss: 0.00000 | Acc: 35.909\n",
      "Epoch 007: | Loss: 0.00000 | Acc: 36.005\n",
      "tensor(0.4050) tensor(0.0658) tensor(-0.1119)\n",
      "tensor(0.3963) tensor(0.0619) tensor(-0.1296)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_RESULTS_BY_SESSION, TEST_RESULTS_BY_SESSION, LOSSES = cross_val_score(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4137e3d",
   "metadata": {
    "id": "d4137e3d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
